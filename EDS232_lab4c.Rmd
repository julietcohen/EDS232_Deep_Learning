---
title: "EDS232 Lab4c Deep Learning - iNaturalist"
author: "Juliet Cohen"
date: "2/20/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1 Deep Learning

You‚Äôll first learn about Computer Vision techniques by going through the Chapter 5 labs:

- 5.1 Introduction to convnets R: html, Rmd ; Python: html, ipynb

- 5.2 Training a convnet from scratch on a small dataset R: html, Rmd ; Python: html, ipynb

The subsequent lab exercises meet the limits of using a CPU over a GPU, which is not available on taylor.bren.ucsb.edu. Here‚Äôs as far as I was able to get for demonstration sake, but you‚Äôre not expected to run this. You might want to try if you have personal computer with a GPU setup.

- 5.3 Using a pretrained convnet R: html, Rmd ; Python: html, ipynb

# 2 iNaturalist

The main lab that you‚Äôll turn in is to apply these techniques to a small subset of the iNaturalist species imagery. These data were downloaded from the links provided at github.com/visipedia/inat_comp:2021/. Of all the 10,000 species and many images for each from training (Train), training mini (Train Mini), validation (Val) and test images, you‚Äôll draw only from the Train Mini set of images. 

The images are available under:

```{r}
librarian::shelf(
  tidyverse, digest, dplyr, DT, glue, purrr, readr, stringr, tidyr, keras, tensorflow)


# install Python into user space
(reticulate::miniconda_path()) # show the Python path
if (!file.exists(reticulate::miniconda_path()))
  reticulate::install_miniconda()
# install keras with tensorflow
if (!keras::is_keras_available())
  keras::install_keras()
```


```{r}
# path to folder containing species directories of images
dir_train_mini <- "/courses/EDS232/inaturalist-2021/train_mini"

# path to output table of paths, which could be read by R, eg read_csv()
inat_spp_dirs_csv <- "~/inat_species_dirs.csv"

# get list of directories, one per species (n = 10,000 species)
dirs_spp <- list.dirs(dir_train_mini, recursive = F)
n_spp <- length(dirs_spp)
n_spp

# set seed (for reproducible results) 
# just before sampling (otherwise get different results)
# based on your username (unique amongst class)
Sys.info()[["user"]] %>% 
  digest::digest2int() %>% 
  set.seed()
i10 <- sample(1:n_spp, 10)

# show the 10 indices sampled of the 10,000 possible 
i10

# show the 10 species directory names
species_10 <- basename(dirs_spp)[i10]
species_10

# show the first 2 species directory names
i2 <- i10[1:2]
species_2 <- basename(dirs_spp)[i2]
species_2
```

```{r}
# create base file paths
base_dir <- base_dir <- "/Users/jscohen/EDS232/lab4/EDS232_Deep_Learning"
train_10_dir <- file.path(base_dir, "train_10")
train_2_dir <- file.path(base_dir, "train_2")
  
validation_10_dir <- file.path(base_dir, "validation_10")
validation_2_dir <- file.path(base_dir, "validation_2")
  
test_10_dir <- file.path(base_dir, "test_10")
test_2_dir <- file.path(base_dir, "test_2")
# create base folders (train, validate, test) for the 10 species and the 2 species 
dir.create(train_10_dir)
dir.create(validation_10_dir)
dir.create(test_10_dir)
dir.create(train_2_dir)
dir.create(validation_2_dir)
dir.create(test_2_dir)
# create folder for all 10 species
for (i in 1:length(species_10)){
  dir.create(file.path(train_10_dir, str_sub(species_10[[i]], start = 1, end = 5)))
  dir.create(file.path(validation_10_dir, str_sub(species_10[[i]], start = 1, end = 5)))
  dir.create(file.path(test_10_dir, str_sub(species_10[[i]], start = 1, end = 5)))
}
# create folder for 2 species
for (i in 1:length(species_2)){
  dir.create(file.path(train_2_dir, str_sub(species_2[[i]], start = 1, end = 5)))
  dir.create(file.path(validation_2_dir, str_sub(species_2[[i]], start = 1, end = 5)))
  dir.create(file.path(test_2_dir, str_sub(species_2[[i]], start = 1, end = 5)))
}
```

```{r}
# path to folder containing species directories of images
original_dataset_dir <- "/courses/EDS232/inaturalist-2021/train_mini"
```


```{r}
# create test, validation, and training groups of images for 10 species
for(i in 1:length(species_10)){
  # create 5 groups of 10 random samples
  species_samples_10 <- replicate(5, 
                                  sample(list.files(paste0(original_dataset_dir, "/", species_10[[i]]), 
                                                    full.names = TRUE), replace = FALSE, 10))
  ## train n = 30 ##
  train <- rbind(species_samples_10[,1], species_samples_10[,2], species_samples_10[,3])
  file.copy(from = train, 
            to = paste0(train_10_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
  ## validation n = 10 ##
  validate <- species_samples_10[,4]
  file.copy(from = validate,
            to = paste0(validation_10_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
  ## train n = 10 ##
  test <- species_samples_10[,5]
  file.copy(from = test,
            to = paste0(test_10_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
}
```

```{r}
# create test, validation, and training groups of images for 2 species
for(i in 1:length(species_2)){
  # create 5 groups of 10 random samples
  species_samples_2 <- replicate(5, 
                                  sample(list.files(paste0(original_dataset_dir, "/", species_10[[i]]), 
                                                    full.names = TRUE), replace = FALSE, 10))
  ## train n = 30 ##
  train <- rbind(species_samples_2[,1], species_samples_2[,2], species_samples_2[,3])
  file.copy(from = train, 
            to = paste0(train_2_dir, "/", str_sub(species_2[[i]], start = 1, end = 5)))
  ## validation n = 10 ##
  validate <- species_samples_2[,4]
  file.copy(from = validate,
            to = paste0(validation_2_dir, "/", str_sub(species_2[[i]], start = 1, end = 5)))
  ## train n = 10 ##
  test <- species_samples_2[,5]
  file.copy(from = test,
            to = paste0(test_2_dir, "/", str_sub(species_2[[i]], start = 1, end = 5)))
}
```

```{r}
# path to output table of paths, which could be read by R, eg read_csv()
inat_spp_dirs_csv <- "~/inat_species_dirs.csv"
```


```{r}
# d <- tibble(
#   # get 10 species names
#   species = basename(dirs_spp)[i10],
#   # assign TRUE/FALSE for: 10 species (multi-class) and 2 species (binary)
#   spp10 = TRUE,
#   spp2  = c(T,T,rep(F,8)))
# DT::datatable(d)
```

```{r}
# # path to output table of paths, which could be read by R, eg read_csv()
# inat_spp_dirs_csv <- "~/inat_species_dirs.csv"
# 
# d <- d %>% 
#   mutate(
#     # construct full path to species directory
#     dir_species = file.path(dir_train_mini, species),
#     tbl_images  = purrr::map(dir_species, function(dir){
#       # create a tibble per species
#       tibble(
#         # list files in the species directory (n=50)
#         image = list.files(dir),
#         # assign subset per species
#         subset = c(rep("train", 30), rep("validation", 10), rep("test", 10))) })) %>% 
#   # go from a tibble with 10 species rows containing a nested tbl_images to unnested, ie 10 species * 50 images = 500 rows
#   tidyr::unnest(tbl_images)
# 
# # write tibble to CSV file for subsequent reading
# readr::write_csv(d, inat_spp_images_csv)
# 
# # show counts of image files per species and subset
# d %>% 
#   mutate(
#     # truncate species to show one line per species
#     species_trunc = stringr::str_trunc(species, 40)) %>% 
#   select(species_trunc, subset) %>% 
#   table()
```

Your task is to apply your deep learning skills to build the following models:

1. 2 Species (binary classification) - neural net. Draw from 3.4 üçø Movies (binary classification). You‚Äôll need to pre-process the images to be a consistent shape first though ‚Äì see 5.2.4 Data preprocessing.

2. 2 Species (binary classification) - convolutional neural net. Draw from the dogs vs cats example.

3. 10 Species (multi-class classification) - neural net. Draw from 3.5 üì∞ Newswires (multi-class classification).

4. 10 Species (multi-class classification) - convolutional neural net. Draw from dogs vs cats example and update necessary values to go from binary to mult-class classification.

In your models, be sure to include the following:

Split the original images per species (n=50) into train (n=30), validate (n=10) and test (n=10). These are almost absurdly few files to feed into these complex deep learning models but will serve as a good learning example.

Include accuracy metric and validation in the fitting process and history plot.

Evaluate loss and accuracy on your test model results. Compare standard neural network and convolutional neural network results.

# model 1 First Attempt

```{r}
# get list of directories, one per species (n = 10,000 species)
dirs_spp <- list.dirs(dir_train_mini, recursive = F)
n_spp <- length(dirs_spp)
# set seed (for reproducible results) 
# just before sampling (otherwise get different results)
# based on your username (unique amongst class)
Sys.info()[["user"]] %>% # sys.info pulls my user name
  digest::digest2int() %>% 
  set.seed()
i10 <- sample(1:n_spp, 10)
# show the 10 indices sampled of the 10,000 possible 
i10
# show the 10 species directory names
species_10 <- basename(dirs_spp)[i10]
species_10
 
# base
base_dir <- "/Users/jscohen/EDS232/lab4/EDS232_Deep_Learning"
train_dir <- file.path(base_dir, "train")
validation_dir <- file.path(base_dir, "validation")
test_dir <- file.path(base_dir, "test")
```

```{r}
 # create base folders (train, validate, test)
 dir.create(train_dir)
 dir.create(validation_dir)
 dir.create(test_dir)
 # create folder for all 10 species
 for (i in 1:length(species_10)){
   dir.create(file.path(train_dir, str_sub(species_10[[i]], start = 1, end = 5)))
   dir.create(file.path(validation_dir, str_sub(species_10[[i]], start = 1, end = 5)))
   dir.create(file.path(test_dir, str_sub(species_10[[i]], start = 1, end = 5)))
 }

# create test, validation, and training groups of images
for(i in 1:length(species_10)){
  # create 5 groups of 10 random samples
  species_samples_10 <- replicate(
    5, sample(list.files(paste0(original_dataset_dir, "/", species_10[[i]]), 
                         full.names = TRUE), replace = FALSE, 10))
  ## train n = 30 ##
  train <- rbind(species_samples_10[,1], species_samples_10[,2], species_samples_10[,3])
  file.copy(from = train, 
            to = paste0(train_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
  ## validation n = 10 ##
  validate <- species_samples_10[,4]
  file.copy(from = validate,
            to = paste0(validation_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
  ## train n = 10 ##
  test <- species_samples_10[,5]
  file.copy(from = test,
            to = paste0(test_dir, "/", str_sub(species_10[[i]], start = 1, end = 5)))
}
```


```{r}
# All images will be rescaled by 1/255
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  # This is the target directory
  train_dir,
  # This is the data generator
  train_datagen,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 20,
  # Since we use binary_crossentropy loss, we need binary labels
  class_mode = "binary")

validation_generator <- flow_images_from_directory(
  validation_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary")
```

```{r}
# vectorize_sequences <- function(sequences, dimension = 10000) {
#   # Create an all-zero matrix of shape (len(sequences), dimension)
#   results <- matrix(0, nrow = length(sequences), ncol = dimension)
#   for (i in 1:length(sequences))
#     # Sets specific indices of results[i] to 1s
#     results[i, sequences[[i]]] <- 1
#   results
# }
# 
# # Our vectorized training data
# x_train <- vectorize_sequences(train_data)
# # Our vectorized test data
# x_test <- vectorize_sequences(test_data)

model <- keras_model_sequential() %>%
  layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>%
  layer_dense(units = 16, activation = "relu") %>%
  layer_dense(units =  1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss      = "binary_crossentropy",
  metrics   = c("accuracy"))

#val_indices <- 1:10000

# x_val <- x_train[val_indices,]
# partial_x_train <- x_train[-val_indices,]
# 
# y_val <- y_train[val_indices]
# partial_y_train <- y_train[-val_indices]
```


```{r}
# batch <- generator_next(train_generator)
# str(batch)
```


```{r}
dir_models <- here::here("train/00348")
dir.create(dir_models, recursive=T, showWarnings = F)
mdl1_h5 <- file.path(dir_models, "species_1.h5")
mdl1_history_rds <- file.path(dir_models, "species_1.rds")
# check if already fitted and saved model
if (!file.exists(mdl1_history_rds) | !file.exists(mdl1_h5)){
  # fit model
  history <- model %>% fit_generator(
    train_generator,
    steps_per_epoch = 5,
    epochs = 7,
    validation_data = validation_generator,
    validation_steps = 3)

  # save fitted model and fitting history
  history %>% saveRDS(mdl1_history_rds)
  model %>% save_model_hdf5(mdl1_h5)
} else{
  # load previously fitted model
  history <- readRDS(mdl1_history_rds)
  model   <- load_model_hdf5(mdl1_h5)
}
```

---------------------------------------------------------------------

# Model 1 Second Attempt

## create initial model

```{r}
# path to output table of paths, which could be read by R, eg read_csv()
inat_spp_dirs_csv <- "~/inat_species_dirs.csv" # I don't see this csv in taylor
# get list of directories, one per species (n = 10,000 species)
dirs_spp <- list.dirs(dir_train_mini, recursive = F)
n_spp <- length(dirs_spp)
# set seed (for reproducible results) 
# just before sampling (otherwise get different results)
# based on your username (unique amongst class)
Sys.info()[["user"]] %>% # sys.info pulls my user name
  digest::digest2int() %>% 
  set.seed()
i10 <- sample(1:n_spp, 10)
# show the 10 indices sampled of the 10,000 possible 
i10
# show the 10 species directory names
species_10 <- basename(dirs_spp)[i10]
species_10
 
# path to folder containing species directories of images
original_dataset_dir <- "/courses/EDS232/inaturalist-2021/train_mini"
# base
base_dir <- "/Users/jscohen/EDS232/lab4/EDS232_Deep_Learning"
train_dir <- file.path(base_dir, "train")
validation_dir <- file.path(base_dir, "validation")
test_dir <- file.path(base_dir, "test")
```

```{r}
# First run everything before Model 1 First Attempt
# code chunk from 5.2.4

# model <- keras_model_sequential() %>% 
#   layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
#                 input_shape = c(150, 150, 3)) %>% 
#   layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
#   layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
#   layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
#   layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
#   layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
#   layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
#   layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
#   layer_flatten() %>% 
#   layer_dense(units = 512, activation = "relu") %>% 
#   layer_dense(units = 1, activation = "sigmoid")
# ```
# 
# ## compile model
# 
# ```{r}
# model %>% compile(
#   loss = "binary_crossentropy",
#   optimizer = optimizer_rmsprop(lr = 1e-4),
#   metrics = c("acc"))
```

# data preprocessing 

```{r}
# code chunk from 5.2.5

# All images will be rescaled by 1/255
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  # This is the target directory
  train_dir,
  # This is the data generator
  train_datagen,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 20,
  # Since we use binary_crossentropy loss, we need binary labels
  class_mode = "binary")

validation_generator <- flow_images_from_directory(
  validation_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary")
```

# might need to insert batch stage here later

```{r}
# chunk from movies example

model <- keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units =  1, activation = "sigmoid")
```


# compile model

```{r}
model %>% compile(
  optimizer = "rmsprop",
  loss      = "binary_crossentropy",
  metrics   = c("accuracy"))


model %>% compile(
  optimizer = optimizer_rmsprop(lr=0.001),
  loss      = "binary_crossentropy",
  metrics   = c("accuracy")) 

model %>% compile(
  optimizer = optimizer_rmsprop(lr = 0.001),
  loss      = loss_binary_crossentropy,
  metrics   = metric_binary_accuracy)
```




















# Model 1 Third Attempt: Binary Classification - Neural Net

### Preprocess Images

```{r}
# All images will be rescaled by 1/255
test_datagen <- image_data_generator(rescale = 1/255)
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_directory(
  # This is the target directory
  train_2_dir,
  # This is the data generator
  train_datagen,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 5,
  # Since we use binary_crossentropy loss, we need binary labels
  class_mode = "binary") 
validation_generator <- flow_images_from_directory(
  validation_2_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "binary")
batch <- generator_next(train_generator)
str(batch)
```

### Build Network 

```{r}
model <- keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(150, 150, 3)) %>%
  layer_flatten() %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units =  1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss      = "binary_crossentropy",
  metrics   = c("accuracy"))

history_1 <- model %>% fit(
    train_generator,
    steps_per_epoch = 5,
    epochs = 30,
    validation_data = validation_generator,
    validation_steps = 5)

plot(history_1)
```

## Output Analysis

insert text here?

### Evaluate
```{r}
test_generator <- flow_images_from_directory(
  test_2_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
model %>% evaluate_generator(test_generator, steps = 50)
```

## Model 2: Binary Classification - Convolutional Neural Net

### Build Network

```{r}
# make the new model  
model <- keras_model_sequential() %>% 
  layer_conv_2d(
    filters = 32, kernel_size = c(3, 3), activation = "relu",
    input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_flatten() %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 512, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")  
  
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc"))
```

### Fit the Model

```{r}
history_2 <- model %>% fit(
    train_generator,
    steps_per_epoch = 5,
    epochs = 30,
    validation_data = validation_generator,
    validation_steps = 5)

history_2
```

```{r}
plot(history_2)
```


### Output Analysis

insert text here?

### Evaluate

```{r}
test_generator_2 <- flow_images_from_directory(
  test_2_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)

model %>% evaluate_generator(test_generator_2, steps = 50)
```



## Model 3: Multi-class Classification - Neural Net

### Preprocess Images

```{r}
# pre process the images from the 10 species using categorical class 
test_datagen_10 <- image_data_generator(rescale = 1/255)
train_datagen_10 <- image_data_generator(rescale = 1/255)
validation_datagen_10 <- image_data_generator(rescale = 1/255)

train_generator_10 <- flow_images_from_directory(
  # This is the target directory
  train_10_dir,
  # This is the data generator
  train_datagen_10,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 5,
  # change label to categorical 
  class_mode = "categorical") 
validation_generator_10 <- flow_images_from_directory(
  validation_10_dir,
  validation_datagen_10,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "categorical")

batch <- generator_next(train_generator_10)
str(batch)
```

### Build Network

```{r}
model <- keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(150, 150, 3)) %>%
  layer_flatten() %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units =  1, activation = "softmax")

# compile
model %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)
```

### Fit Model

```{r}
history_3 <- model %>% fit(
  train_generator_10,
  steps_per_epoch = 5,
  epochs = 30,
  validation_data = validation_generator_10,
  validation_steps = 5)

history_3
```

```{r}
plot(history_3)
```


### Output Analysis

insert text here?

### Evaluate Model

```{r}
test_generator_3 <- flow_images_from_directory(
  test_10_dir,
  test_datagen_10,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "categorical"
)
model %>% evaluate_generator(test_generator_3, steps = 50)
```

## Model 4: Multi-Class Classification - Convolutional Neural Nets

### Build Network 

```{r}
model <- keras_model_sequential() %>% 
  layer_conv_2d(
    filters = 32, kernel_size = c(3, 3), activation = "relu",
    input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_flatten() %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 512, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")  
  
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc"))
```

### Fit Model

```{r}
history_4 <- model %>% fit(
    train_generator_10,
    steps_per_epoch = 5,
    epochs = 30,
    validation_data = validation_generator_10,
    validation_steps = 5)

history_4
```

```{r}
plot(history_4)
```

### Output Analysis

insert text here?

```{r}
test_generator_4 <- flow_images_from_directory(
  test_10_dir,
  test_datagen_10,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "categorical"
)
model %>% evaluate_generator(test_generator_4, steps = 50)
```



























